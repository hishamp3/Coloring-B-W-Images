{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885f6539",
   "metadata": {},
   "source": [
    "# Coloring B&W images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd3388",
   "metadata": {},
   "source": [
    "#### Using OpenCv library for performing computer vision related operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9c7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "backend.clear_session()\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf60cc3",
   "metadata": {},
   "source": [
    "#### Converting RGB image to LAB space image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14127dc0",
   "metadata": {},
   "source": [
    "The CIELAB color space, also referred to as L*a*b* , is a color space defined by the International Commission on Illumination.t expresses color as three values: L* for perceptual lightness, and a* and b* for the four unique colors of human vision: red, green, blue, and yellow. CIELAB was intended as a perceptually uniform space, where a given numerical change corresponds to a similar perceived change in color. While the LAB space is not truly perceptually uniform, it nevertheless is useful in industry for detecting small differences in color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d21e94a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340, 638, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#load RGB image\n",
    "original_img = cv2.imread('girl.jpg')\n",
    "print(original_img.shape)\n",
    "\n",
    "#convert GRAY to LAB image\n",
    "lab_image = cv2.cvtColor(original_img, cv2.COLOR_RGB2LAB)\n",
    "lab_image = np.array(lab_image, dtype=float)\n",
    "\n",
    "X = lab_image[:,:,0]*(1.0/255)\n",
    "Y = lab_image[:,:,1:]*(1.0/255)\n",
    "\n",
    "Y = Y/128\n",
    "X = X.reshape(1, lab_image.shape[0], lab_image.shape[1], 1)\n",
    "Y = Y.reshape(1, lab_image.shape[0], lab_image.shape[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc613ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network   \n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(None, None,1)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9d0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish model\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365d198",
   "metadata": {},
   "source": [
    "#### Increase epochs for Improving efficiency of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35cfa386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000/2000\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 5.9724e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ba07df34c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, \n",
    "    y=Y,\n",
    "    batch_size=1,\n",
    "    epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77af9eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 540ms/step - loss: 5.4680e-08\n",
      "5.4679738070717576e-08\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X, Y, batch_size=1))\n",
    "output = model.predict(X)\n",
    "output *= 128*255\n",
    "X*=255\n",
    "# Output colorizations\n",
    "cur = np.zeros((lab_image.shape[0],lab_image.shape[1], 3), dtype=np.uint8)\n",
    "cur[:,:,0] = X[0][:,:,0]\n",
    "cur[:,:,1:] = output[0]\n",
    "\n",
    "output_image = cv2.cvtColor(cur, cv2.COLOR_LAB2RGB)\n",
    "Input_image = cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a82c2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Ouput', output_image)\n",
    "cv2.imshow('Input', Input_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4e36a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
